{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80Uk0TYTILoT",
        "outputId": "03dc7fa7-a704-44a1-cc24-3f0a11c2a6b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "gradio_app.py  model_emnist.h5\tmodel_utils.py\t__pycache__  train.py\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# 1. Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Pindah ke folder project kamu (Ganti nama foldernya sesuai di Drive kamu)\n",
        "path = \"/content/drive/MyDrive/citra digital\"\n",
        "os.chdir(path)\n",
        "\n",
        "# 3. Cek apakah file sudah ada\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# 1. Hapus cache lama yang rusak\n",
        "!rm -rf /root/.cache/emnist\n",
        "\n",
        "# 2. Buat folder baru yang bersih\n",
        "os.makedirs('/root/.cache/emnist', exist_ok=True)\n",
        "print(\"âœ… Folder cache telah dibersihkan dan siap.\")\n",
        "\n",
        "#ini dipakai jika train.py tidak mau mentrain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbgqR-DoN7Y6",
        "outputId": "1a0d87c4-1799-4ae0-b229-0affea2c4d8d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Folder cache telah dibersihkan dan siap.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download langsung file zip dataset\n",
        "!wget -O /root/.cache/emnist/emnist.zip https://biometrics.nist.gov/cs_links/EMNIST/gzip.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adMQjwz6JRMh",
        "outputId": "3ebde31a-3dbe-4712-dc70-06d6e3e78525"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-20 10:16:01--  https://biometrics.nist.gov/cs_links/EMNIST/gzip.zip\n",
            "Resolving biometrics.nist.gov (biometrics.nist.gov)... 172.65.90.26, 172.65.90.24, 172.65.90.27, ...\n",
            "Connecting to biometrics.nist.gov (biometrics.nist.gov)|172.65.90.26|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 561753746 (536M) [application/zip]\n",
            "Saving to: â€˜/root/.cache/emnist/emnist.zipâ€™\n",
            "\n",
            "/root/.cache/emnist 100%[===================>] 535.73M   254MB/s    in 2.1s    \n",
            "\n",
            "2025-12-20 10:16:04 (254 MB/s) - â€˜/root/.cache/emnist/emnist.zipâ€™ saved [561753746/561753746]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rJrFNfvNltj",
        "outputId": "e0eafe93-8e1c-472f-81c3-f0c118394ca3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-20 10:16:06.614491: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766225766.633163   14673 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766225766.638743   14673 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766225766.652568   14673 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766225766.652597   14673 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766225766.652601   14673 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766225766.652605   14673 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-20 10:16:06.656918: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "ğŸ“¥ Mengakses dataset yang sudah didownload manual...\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "2025-12-20 10:16:13.983069: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1766225773.983218   14673 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "ğŸš€ Memulai Training...\n",
            "Epoch 1/10\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1766225776.559231   14721 service.cc:152] XLA service 0x7e96b400b980 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1766225776.559261   14721 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2025-12-20 10:16:16.585508: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1766225776.756427   14721 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "2025-12-20 10:16:17.101022: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.6 = (f32[128,32,26,26]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,1,28,28]{3,2,1,0} %bitcast.4265, f32[32,1,3,3]{3,2,1,0} %bitcast.4272, f32[32]{0} %bitcast.4738), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-12-20 10:16:17.149092: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.7 = (f32[128,64,11,11]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,32,13,13]{3,2,1,0} %bitcast.4802, f32[64,32,3,3]{3,2,1,0} %bitcast.4292, f32[64]{0} %bitcast.4862), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "I0000 00:00:1766225778.744895   14721 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m869/882\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5978 - loss: 1.41922025-12-20 10:16:22.249832: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.6 = (f32[32,32,26,26]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,28,28]{3,2,1,0} %bitcast.4265, f32[32,1,3,3]{3,2,1,0} %bitcast.4272, f32[32]{0} %bitcast.4738), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-12-20 10:16:22.259638: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.7 = (f32[32,64,11,11]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,13,13]{3,2,1,0} %bitcast.4802, f32[64,32,3,3]{3,2,1,0} %bitcast.4292, f32[64]{0} %bitcast.4862), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "\u001b[1m882/882\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5998 - loss: 1.41122025-12-20 10:16:24.301055: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.6 = (f32[128,32,26,26]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,1,28,28]{3,2,1,0} %bitcast.499, f32[32,1,3,3]{3,2,1,0} %bitcast.506, f32[32]{0} %bitcast.508), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-12-20 10:16:24.324613: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.7 = (f32[128,64,11,11]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,32,13,13]{3,2,1,0} %bitcast.515, f32[64,32,3,3]{3,2,1,0} %bitcast.522, f32[64]{0} %bitcast.524), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-12-20 10:16:25.314745: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.6 = (f32[112,32,26,26]{3,2,1,0}, u8[0]{0}) custom-call(f32[112,1,28,28]{3,2,1,0} %bitcast.499, f32[32,1,3,3]{3,2,1,0} %bitcast.506, f32[32]{0} %bitcast.508), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-12-20 10:16:25.347284: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.7 = (f32[112,64,11,11]{3,2,1,0}, u8[0]{0}) custom-call(f32[112,32,13,13]{3,2,1,0} %bitcast.515, f32[64,32,3,3]{3,2,1,0} %bitcast.522, f32[64]{0} %bitcast.524), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "\u001b[1m882/882\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5999 - loss: 1.4106 - val_accuracy: 0.8447 - val_loss: 0.4686\n",
            "Epoch 2/10\n",
            "\u001b[1m882/882\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8319 - loss: 0.4964 - val_accuracy: 0.8585 - val_loss: 0.4087\n",
            "Epoch 3/10\n",
            "\u001b[1m882/882\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8557 - loss: 0.4074 - val_accuracy: 0.8687 - val_loss: 0.3811\n",
            "Epoch 4/10\n",
            "\u001b[1m882/882\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8678 - loss: 0.3709 - val_accuracy: 0.8751 - val_loss: 0.3624\n",
            "Epoch 5/10\n",
            "\u001b[1m882/882\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8758 - loss: 0.3454 - val_accuracy: 0.8797 - val_loss: 0.3480\n",
            "Epoch 6/10\n",
            "\u001b[1m882/882\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8844 - loss: 0.3158 - val_accuracy: 0.8794 - val_loss: 0.3490\n",
            "Epoch 7/10\n",
            "\u001b[1m882/882\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8880 - loss: 0.3010 - val_accuracy: 0.8824 - val_loss: 0.3418\n",
            "Epoch 8/10\n",
            "\u001b[1m882/882\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8928 - loss: 0.2830 - val_accuracy: 0.8860 - val_loss: 0.3346\n",
            "Epoch 9/10\n",
            "\u001b[1m882/882\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8973 - loss: 0.2688 - val_accuracy: 0.8832 - val_loss: 0.3514\n",
            "Epoch 10/10\n",
            "\u001b[1m882/882\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9038 - loss: 0.2482 - val_accuracy: 0.8816 - val_loss: 0.3433\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "âœ… Model BERHASIL disimpan sebagai 'model_emnist.h5'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Jalankan UI Gradio\n",
        "!python gradio_app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CAkeidMOisS",
        "outputId": "c01d8400-bb20-4cfa-efbc-b3dd7a913f8c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-20 10:17:08.762731: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766225828.789555   15146 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766225828.799403   15146 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766225828.815188   15146 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766225828.815217   15146 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766225828.815221   15146 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766225828.815226   15146 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-20 10:17:08.819479: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-12-20 10:17:14.844417: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1766225834.844575   15146 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* Running on public URL: https://28cc07c753d6f80306.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1766225866.204924   15205 service.cc:152] XLA service 0x7b4898009c50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1766225866.204956   15205 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2025-12-20 10:17:46.212010: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1766225866.239835   15205 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "2025-12-20 10:17:46.541707: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.7 = (f32[1,64,11,11]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,32,13,13]{3,2,1,0} %bitcast.212, f32[64,32,3,3]{3,2,1,0} %bitcast.219, f32[64]{0} %bitcast.221), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "I0000 00:00:1766225866.829084   15205 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Created dataset file at: .gradio/flagged/dataset3.csv\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://28cc07c753d6f80306.gradio.live\n"
          ]
        }
      ]
    }
  ]
}